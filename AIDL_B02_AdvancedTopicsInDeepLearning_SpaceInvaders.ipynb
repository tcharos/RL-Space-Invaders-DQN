{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tcharos/AIDL_B02-Advanced-Topics-in-Deep-Learning/blob/main/AIDL_B02_AdvancedTopicsInDeepLearning_SpaceInvaders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkZJMnJp0uUq"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tcharos/AIDL_B02-Advanced-Topics-in-Deep-Learning/blob/main/AIDL_B02_AdvancedTopicsInDeepLearning_SpaceInvaders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# üöÄ Project Base: DQN Variants for ALE/SpaceInvaders-v5\n",
        "\n",
        "This notebook strictly implements the project's requirements for the **`ALE/SpaceInvaders-v5`** environment with 4-frame stacking and CNN architecture.\n",
        "\n",
        "**Key Requirements Met:**\n",
        "* **Environment:** `ALE/SpaceInvaders-v5` [cite: 11]\n",
        "* **Action Space:** 6 actions [cite: 13, 21]\n",
        "* **State:** 4 stacked input frames [cite: 19]\n",
        "\n",
        "**To run an implementation:**\n",
        "1.  Change the `CONFIG['MODE']` variable below to one of: **`SimpleDQN`**, **`DoubleDQN`**, or **`DuelingDQN`**.\n",
        "2.  Adjust hyperparameters (`LR`, `EPS_DECAY`, etc.) in the `CONFIG` dictionary if needed.\n",
        "3.  Run all cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## 1. Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e7adb2-f2b7-4d1b-b3dc-c6d2ff9a7898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.12/dist-packages (0.11.2)\n",
            "Requirement already satisfied: gymnasium[accept-rom-license,atari,other] in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "\u001b[33mWARNING: gymnasium 1.2.2 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari,other]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari,other]) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari,other]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari,other]) (0.0.4)\n",
            "Requirement already satisfied: moviepy>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari,other]) (1.0.3)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari,other]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari,other]) (4.12.0.88)\n",
            "Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license,atari,other]) (0.13.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->gymnasium[accept-rom-license,atari,other]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->gymnasium[accept-rom-license,atari,other]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->gymnasium[accept-rom-license,atari,other]) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->gymnasium[accept-rom-license,atari,other]) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->gymnasium[accept-rom-license,atari,other]) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->gymnasium[accept-rom-license,atari,other]) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->gymnasium[accept-rom-license,atari,other]) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->gymnasium[accept-rom-license,atari,other]) (2.9.0.post0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy>=1.0.0->gymnasium[accept-rom-license,atari,other]) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.12/dist-packages (from moviepy>=1.0.0->gymnasium[accept-rom-license,atari,other]) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from moviepy>=1.0.0->gymnasium[accept-rom-license,atari,other]) (2.32.4)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy>=1.0.0->gymnasium[accept-rom-license,atari,other]) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy>=1.0.0->gymnasium[accept-rom-license,atari,other]) (2.37.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy>=1.0.0->gymnasium[accept-rom-license,atari,other]) (0.6.0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn>=0.13->gymnasium[accept-rom-license,atari,other]) (2.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn>=0.13->gymnasium[accept-rom-license,atari,other]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn>=0.13->gymnasium[accept-rom-license,atari,other]) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->gymnasium[accept-rom-license,atari,other]) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gymnasium[accept-rom-license,atari,other]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gymnasium[accept-rom-license,atari,other]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gymnasium[accept-rom-license,atari,other]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gymnasium[accept-rom-license,atari,other]) (2025.11.12)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.12/dist-packages (3.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+5build2).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.16).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "Requirement already satisfied: shimmy in /usr/local/lib/python3.12/dist-packages (2.0.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.12/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from shimmy) (2.0.2)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /usr/local/lib/python3.12/dist-packages (from shimmy) (1.2.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=1.0.0a1->shimmy) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=1.0.0a1->shimmy) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=1.0.0a1->shimmy) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install \"gymnasium[atari,accept-rom-license,other]\" ale-py\n",
        "!pip install pyvirtualdisplay\n",
        "!apt-get install -y xvfb x11-utils\n",
        "!pip install shimmy imageio-ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "config"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import deque, namedtuple\n",
        "import matplotlib.pyplot as plt\n",
        "from gymnasium.wrappers import AtariPreprocessing\n",
        "from gymnasium.wrappers import FrameStackObservation\n",
        "import ale_py\n",
        "\n",
        "import gc\n",
        "import psutil\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Tools for video display\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "from base64 import b64encode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- GLOBAL CONFIGURATION -----------------\n",
        "CONFIG = {\n",
        "    \"ENV_ID\": 'ALE/SpaceInvaders-v5',\n",
        "    \"SEED\": 2,\n",
        "    \"MODE\": \"SimpleDQN\", # 'SimpleDQN', 'DoubleDQN', 'DuelingDQN'\n",
        "    \"INPUT_SHAPE\": (4, 84, 84), # 4 stacked frames, resized to 84x84\n",
        "    \"BUFFER_SIZE\": int(5e4), # also checked 1e5, 1e4 (10000), 5e3 (5000), 7.5e3 (7500)\n",
        "    \"BATCH_SIZE\": 64, # Reduced batch size\n",
        "    \"GAMMA\": 0.99, # Prioritize long-term cumulative reward\n",
        "    \"TAU\": 1e-3, # Soft Update Rate\n",
        "    \"LR\": 2e-4, # Also tried 1e-4, 5e-5. Lower learning rate --> stable convergence\n",
        "    \"UPDATE_EVERY\": 4, # Learn frequency\n",
        "    \"TARGET_UPDATE_FREQ\": 1000, # Also tried 1000\n",
        "    \"N_EPISODES\": 5000,\n",
        "    \"EPS_START\": 1.0, # Initial probability of choosing a random action (exploration) --> fully exploring the environment to gather initial experiences\n",
        "    \"EPS_END\": 0.01, # Also chekced 0.01. Minimum probability of choosing a random action.\n",
        "    \"EPS_DECAY\": 0.9996, # Also checked 0.999, 0.995\n",
        "    \"USE_GOOGLE_DRIVE\": True,\n",
        "    \"CHECKPOINT_FREQ\": 400,\n",
        "    \"GOAL_SCORE\": 400.0\n",
        "}\n",
        "\n",
        "CONFIG_DUELING = {\n",
        "    \"ENV_ID\": 'ALE/SpaceInvaders-v5',\n",
        "    \"SEED\": 999,\n",
        "    \"MODE\": \"DuelingDQN\",\n",
        "    \"INPUT_SHAPE\": (4, 84, 84),\n",
        "    \"BUFFER_SIZE\": int(5e4),       # 50k buffer\n",
        "    \"BATCH_SIZE\": 64,               # Large batches\n",
        "    \"GAMMA\": 0.99,\n",
        "    \"TAU\": 1e-3,\n",
        "    \"LR\": 2.5e-4,                   # Increased from 1.5e-4 (more aggressive learning)\n",
        "    \"UPDATE_EVERY\": 4,\n",
        "    \"TARGET_UPDATE_FREQ\": 1000,\n",
        "    \"N_EPISODES\": 5000,            # Increased to 10k (need more time)\n",
        "    \"EPS_START\": 1.0,\n",
        "    \"EPS_END\": 0.01,\n",
        "    \"EPS_DECAY\": 0.9996,            # Slightly faster than 0.9997\n",
        "    \"USE_GOOGLE_DRIVE\": True,\n",
        "    \"CHECKPOINT_FREQ\": 100,\n",
        "    \"GOAL_SCORE\": 400.0\n",
        "}\n",
        "\n",
        "CONFIG_DOUBLE = {\n",
        "    \"ENV_ID\": 'ALE/SpaceInvaders-v5',\n",
        "    \"SEED\": 789,\n",
        "    \"MODE\": \"DoubleDQN\",\n",
        "    \"INPUT_SHAPE\": (4, 84, 84),\n",
        "    \"BUFFER_SIZE\": int(5e4),\n",
        "    \"BATCH_SIZE\": 64,\n",
        "    \"GAMMA\": 0.99,\n",
        "    \"TAU\": 1e-3,\n",
        "    \"LR\": 2.5e-4,                # Same as DuelingDQN\n",
        "    \"UPDATE_EVERY\": 4,\n",
        "    \"TARGET_UPDATE_FREQ\": 1000,\n",
        "    \"N_EPISODES\": 5000,          # Slightly less than Dueling\n",
        "    \"EPS_START\": 1.0,\n",
        "    \"EPS_END\": 0.01,\n",
        "    \"EPS_DECAY\": 0.9996,\n",
        "    \"USE_GOOGLE_DRIVE\": True,\n",
        "    \"CHECKPOINT_FREQ\": 100,\n",
        "    \"GOAL_SCORE\": 400.0\n",
        "}\n",
        "# --------------------------------------------------------\n",
        "\n",
        "gym.register_envs(ale_py)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "random.seed(CONFIG['SEED'])\n",
        "np.random.seed(CONFIG['SEED'])\n",
        "torch.manual_seed(CONFIG['SEED'])\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(CONFIG['SEED'])\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Current DQN Mode: {CONFIG['MODE']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSTjoTix3Zdq",
        "outputId": "dc21d9a5-4fef-4a8a-a64b-f2d29edb4b14"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "Current DQN Mode: SimpleDQN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print configuration\n",
        "def print_config():\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"CURRENT CONFIGURATION - SimpleDQN Aggressive\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Environment:          {CONFIG['ENV_ID']}\")\n",
        "    print(f\"Seed:                 {CONFIG['SEED']}\")\n",
        "    print(f\"Mode:                 {CONFIG['MODE']}\")\n",
        "    print(f\"Buffer Size:          {CONFIG['BUFFER_SIZE']:,} experiences\")\n",
        "    print(f\"Batch Size:           {CONFIG['BATCH_SIZE']}\")\n",
        "    print(f\"Learning Rate:        {CONFIG['LR']}\")\n",
        "    print(f\"Gamma:                {CONFIG['GAMMA']}\")\n",
        "    print(f\"Update Every:         {CONFIG['UPDATE_EVERY']} steps\")\n",
        "    print(f\"Target Update Freq:   {CONFIG['TARGET_UPDATE_FREQ']} steps\")\n",
        "    print(f\"Episodes:             {CONFIG['N_EPISODES']}\")\n",
        "    print(f\"Epsilon Start:        {CONFIG['EPS_START']}\")\n",
        "    print(f\"Epsilon End:          {CONFIG['EPS_END']}\")\n",
        "    print(f\"Epsilon Decay:        {CONFIG['EPS_DECAY']}\")\n",
        "    print(f\"Checkpoint Freq:      {CONFIG['CHECKPOINT_FREQ']} episodes\")\n",
        "    print(\"=\"*70)"
      ],
      "metadata": {
        "id": "f6mh-9y1ix7v"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if CONFIG['USE_GOOGLE_DRIVE']:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    checkpoint_dir = '/content/drive/MyDrive/DQN_Checkpoints'\n",
        "    print(\"‚úì Google Drive mounted - checkpoints will be saved to Drive\")\n",
        "else:\n",
        "    checkpoint_dir = './checkpoints'  # Local directory\n",
        "    print(\"‚úì Using local storage - checkpoints will be saved locally\")\n",
        "\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_nOa0elCNZL",
        "outputId": "e4bfbeda-8f78-43d9-81b0-61c9626a9cbd"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úì Google Drive mounted - checkpoints will be saved to Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "env_init"
      },
      "source": [
        "## 2. Environment Initialization\n",
        "We use **`AtariPreprocessing`** to handle resizing/cropping to 84x84 and grayscale conversion. **`FrameStack`** then stacks 4 consecutive frames, fulfilling the requirements for the state space[cite: 19, 20]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "env_run",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a30eff3e-30b5-4af6-e8e0-fd9a7a0caeed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final State shape (Stacked Frames): (4, 84, 84)\n",
            "Number of available actions (SpaceInvaders): 6\n"
          ]
        }
      ],
      "source": [
        "def make_atari_env(env_id, seed):\n",
        "    \"\"\"Creates and wraps the Atari environment with standard preprocessing and 4-frame stacking.\"\"\"\n",
        "    # 1. Base Environment (Using the required ID [cite: 11])\n",
        "    env = gym.make(env_id)\n",
        "\n",
        "    # 2. Atari Preprocessing: Resizes to 84x84, grayscale, handles max-pooling/skip.\n",
        "    # Frame skip is set to 1 here because the ALE/SpaceInvaders-v5 environment generally handles skips\n",
        "    # implicitly, or we rely on the standard wrappers' internal logic for compatibility.\n",
        "    env = AtariPreprocessing(env, grayscale_obs=True, terminal_on_life_loss=True, frame_skip=1, screen_size=84)\n",
        "\n",
        "    # 3. Frame Stacking (Creates the (4, 84, 84) state [cite: 19])\n",
        "    env = FrameStackObservation(env, stack_size=4)\n",
        "\n",
        "    # Set seed on the final environment\n",
        "    if seed is not None:\n",
        "        env.action_space.seed(seed)\n",
        "        env.observation_space.seed(seed)\n",
        "\n",
        "    return env\n",
        "\n",
        "env = make_atari_env(CONFIG['ENV_ID'], CONFIG['SEED'])\n",
        "action_size = env.action_space.n\n",
        "state_shape = env.observation_space.shape\n",
        "\n",
        "print(f'Final State shape (Stacked Frames): {state_shape}')\n",
        "print(f'Number of available actions (SpaceInvaders): {action_size}') # Confirms 6 actions [cite: 13, 21]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "network_arch"
      },
      "source": [
        "## 3. Q-Network Architecture\n",
        "The network uses a CNN architecture  to process the high-dimensional image input, supporting Dueling components via a flag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "QNetwork_code"
      },
      "outputs": [],
      "source": [
        "class QNetwork(nn.Module):\n",
        "    \"\"\"Enhanced Q-Network with BatchNorm - supports both Standard and Dueling architectures.\"\"\"\n",
        "\n",
        "    def __init__(self, state_shape, action_size, seed, dueling=False):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "        self.dueling = dueling\n",
        "        in_channels = state_shape[0]  # 4 stacked frames\n",
        "\n",
        "        # Enhanced CNN layers with BatchNorm\n",
        "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=8, stride=4)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1)  # Increased to 128\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # Calculate fc_input_size dynamically\n",
        "        dummy_input = torch.zeros(1, *state_shape)\n",
        "        x = self._forward_conv(dummy_input)\n",
        "        self.fc_input_size = x.view(1, -1).size(1)\n",
        "\n",
        "        if self.dueling:\n",
        "            # Value stream (estimates state value)\n",
        "            self.fc_v1 = nn.Linear(self.fc_input_size, 512)\n",
        "            self.fc_v2 = nn.Linear(512, 256)\n",
        "            self.fc_v3 = nn.Linear(256, 1)\n",
        "\n",
        "            # Advantage stream (estimates action advantages)\n",
        "            self.fc_a1 = nn.Linear(self.fc_input_size, 512)\n",
        "            self.fc_a2 = nn.Linear(512, 256)\n",
        "            self.fc_a3 = nn.Linear(256, action_size)\n",
        "\n",
        "            self.dropout = nn.Dropout(0.1)\n",
        "        else:\n",
        "            # Standard Q-value stream\n",
        "            self.fc1 = nn.Linear(self.fc_input_size, 512)\n",
        "            self.fc2 = nn.Linear(512, 256)\n",
        "            self.fc3 = nn.Linear(256, action_size)\n",
        "\n",
        "            self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def _forward_conv(self, x):\n",
        "        \"\"\"Forward pass through convolutional layers with BatchNorm.\"\"\"\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "    def forward(self, state):\n",
        "        \"\"\"Forward pass through the entire network.\"\"\"\n",
        "        x = self._forward_conv(state)\n",
        "\n",
        "        if self.dueling:\n",
        "            # Value stream\n",
        "            v = F.relu(self.fc_v1(x))\n",
        "            v = F.relu(self.fc_v2(v))\n",
        "            v = self.dropout(v)\n",
        "            v = self.fc_v3(v)\n",
        "\n",
        "            # Advantage stream\n",
        "            a = F.relu(self.fc_a1(x))\n",
        "            a = F.relu(self.fc_a2(a))\n",
        "            a = self.dropout(a)\n",
        "            a = self.fc_a3(a)\n",
        "\n",
        "            # Dueling aggregation: Q(s,a) = V(s) + (A(s,a) - mean(A(s,a)))\n",
        "            return v + a - a.mean(1, keepdim=True)\n",
        "        else:\n",
        "            # Standard path\n",
        "            x = F.relu(self.fc1(x))\n",
        "            x = F.relu(self.fc2(x))\n",
        "            x = self.dropout(x)\n",
        "            return self.fc3(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_network_architecture(network):\n",
        "    \"\"\"Print detailed network architecture and parameter count.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"NEURAL NETWORK ARCHITECTURE\")\n",
        "    print(\"=\"*70)\n",
        "    print(network)\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    total_params = sum(p.numel() for p in network.parameters())\n",
        "    trainable_params = sum(p.numel() for p in network.parameters() if p.requires_grad)\n",
        "\n",
        "    print(f\"\\nTotal Parameters:      {total_params:,}\")\n",
        "    print(f\"Trainable Parameters:  {trainable_params:,}\")\n",
        "    print(f\"Architecture Type:     {'Dueling' if network.dueling else 'Standard'}\")\n",
        "\n",
        "    # Show output shape\n",
        "    print(\"\\nLayer Output Shapes:\")\n",
        "    dummy = torch.zeros(1, 4, 84, 84).to(device)\n",
        "    conv_out = network._forward_conv(dummy)\n",
        "    print(f\"  Conv output:  {conv_out.shape}\")\n",
        "    out = network(dummy)\n",
        "    print(f\"  Final output: {out.shape}\")\n",
        "\n",
        "    print(\"=\"*70 + \"\\n\")"
      ],
      "metadata": {
        "id": "GCz3WNEfnwwc"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buffer_agents"
      },
      "source": [
        "## 4. Replay Buffer and Agent Implementations\n",
        "The **Replay Buffer** (PER is an optional extension [cite: 27]) is crucial for breaking correlation in experience samples. The **AgentBase** handles common functions; specialized classes implement the specific Q-learning update rule."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "ReplayBuffer_code"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer:\n",
        "    \"\"\"Memory-efficient replay buffer using uint8 for frames.\"\"\"\n",
        "\n",
        "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=buffer_size)\n",
        "        self.batch_size = batch_size\n",
        "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "        self.seed = random.seed(seed)\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Store frames as uint8 to save memory (4x compression).\"\"\"\n",
        "        # Convert float32 [0,1] to uint8 [0,255]\n",
        "        if state.dtype == np.float32 or state.dtype == np.float64:\n",
        "            state = (state * 255).astype(np.uint8)\n",
        "        if next_state.dtype == np.float32 or next_state.dtype == np.float64:\n",
        "            next_state = (next_state * 255).astype(np.uint8)\n",
        "\n",
        "        e = self.experience(state, action, reward, next_state, done)\n",
        "        self.memory.append(e)\n",
        "\n",
        "    def sample(self):\n",
        "        \"\"\"Sample and convert back to float32 [0,1].\"\"\"\n",
        "        experiences = random.sample(self.memory, k=self.batch_size)\n",
        "\n",
        "        states = torch.from_numpy(np.stack([e.state for e in experiences])).float().to(device) / 255.0\n",
        "        actions = torch.from_numpy(np.vstack([e.action for e in experiences])).long().to(device)\n",
        "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences])).float().to(device)\n",
        "        next_states = torch.from_numpy(np.stack([e.next_state for e in experiences])).float().to(device) / 255.0\n",
        "        dones = torch.from_numpy(np.vstack([e.done for e in experiences]).astype(np.uint8)).float().to(device)\n",
        "\n",
        "        return (states, actions, rewards, next_states, dones)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "Agent_init",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3b1c9b6-9874-4633-ca7c-33bdb34bb2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized agent: SimpleDQNAgent with learning mode: SimpleDQN\n",
            "\n",
            "======================================================================\n",
            "NEURAL NETWORK ARCHITECTURE\n",
            "======================================================================\n",
            "QNetwork(\n",
            "  (conv1): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=6272, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=6, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "======================================================================\n",
            "\n",
            "Total Parameters:      3,460,006\n",
            "Trainable Parameters:  3,460,006\n",
            "Architecture Type:     Standard\n",
            "\n",
            "Layer Output Shapes:\n",
            "  Conv output:  torch.Size([1, 6272])\n",
            "  Final output: torch.Size([1, 6])\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class AgentBase:\n",
        "    \"\"\"Base class for all DQN agents, handling shared components and target network logic.\"\"\"\n",
        "\n",
        "    def __init__(self, state_shape, action_size, seed, mode, dueling):\n",
        "        self.state_shape = state_shape\n",
        "        self.action_size = action_size\n",
        "        self.mode = mode\n",
        "\n",
        "        # Initialize Q-Networks\n",
        "        self.qnetwork_local = QNetwork(state_shape, action_size, seed, dueling=dueling).to(device)\n",
        "        self.qnetwork_target = QNetwork(state_shape, action_size, seed, dueling=dueling).to(device)\n",
        "        self.qnetwork_target.load_state_dict(self.qnetwork_local.state_dict())\n",
        "\n",
        "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=CONFIG['LR'])\n",
        "        self.memory = ReplayBuffer(action_size, CONFIG['BUFFER_SIZE'], CONFIG['BATCH_SIZE'], seed)\n",
        "\n",
        "        self.t_step = 0\n",
        "\n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "      # Convert LazyFrames to numpy if needed\n",
        "      if hasattr(state, '__array__'):\n",
        "          state = np.array(state)\n",
        "      if hasattr(next_state, '__array__'):\n",
        "          next_state = np.array(next_state)\n",
        "\n",
        "      # Save experience\n",
        "      self.memory.add(state, action, reward, next_state, done)\n",
        "\n",
        "      # Learn every UPDATE_EVERY steps\n",
        "      self.t_step = (self.t_step + 1) % CONFIG['UPDATE_EVERY']\n",
        "      if self.t_step == 0:\n",
        "          if len(self.memory) > CONFIG['BATCH_SIZE']:\n",
        "              experiences = self.memory.sample()\n",
        "              self.learn(experiences, CONFIG['GAMMA'])\n",
        "              # CRITICAL: Delete experiences tuple to free memory\n",
        "              del experiences\n",
        "\n",
        "      # Hard update the target network periodically\n",
        "      # FIX: This condition was wrong - it would almost never trigger\n",
        "      if (self.t_step + 1) % CONFIG['TARGET_UPDATE_FREQ'] == 0:\n",
        "          self.qnetwork_target.load_state_dict(self.qnetwork_local.state_dict())\n",
        "\n",
        "    def act(self, state, eps=0.):\n",
        "      \"\"\"Returns action based on epsilon-greedy policy.\"\"\"\n",
        "      # Convert LazyFrames to numpy if needed\n",
        "      if hasattr(state, '__array__'):\n",
        "          state = np.array(state)\n",
        "\n",
        "      state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "\n",
        "      self.qnetwork_local.eval()\n",
        "      with torch.no_grad():\n",
        "          action_values = self.qnetwork_local(state)\n",
        "      self.qnetwork_local.train()\n",
        "\n",
        "      if random.random() > eps:\n",
        "          return np.argmax(action_values.cpu().data.numpy())\n",
        "      else:\n",
        "          return random.choice(np.arange(self.action_size))\n",
        "\n",
        "    def learn(self, experiences, gamma):\n",
        "        # Placeholder, implemented by child classes\n",
        "        pass\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# --- üí• DQN Variant 1: Simple DQN (Original Target Calculation) ---\n",
        "# ----------------------------------------------------------------\n",
        "class SimpleDQNAgent(AgentBase):\n",
        "    \"\"\"Implements the original DQN learning step: Target Q = R + gamma * max_a Q_target(s', a).\"\"\"\n",
        "    def __init__(self, state_shape, action_size, seed):\n",
        "        # Initialize with Standard QNetwork (dueling=False)\n",
        "        super().__init__(state_shape, action_size, seed, mode='SimpleDQN', dueling=False)\n",
        "\n",
        "    def learn(self, experiences, gamma):\n",
        "        states, actions, rewards, next_states, dones = experiences\n",
        "\n",
        "        # Ensure states have the right shape: (batch, 4, 84, 84)\n",
        "        if states.dim() == 5:  # If shape is (batch, 4, 1, 84, 84)\n",
        "            states = states.squeeze(2)\n",
        "        if next_states.dim() == 5:\n",
        "            next_states = next_states.squeeze(2)\n",
        "\n",
        "        # Target Q calculation uses the max Q-value from the target network directly.\n",
        "        with torch.no_grad():  # ‚Üê CRITICAL: Prevent gradient tracking for target\n",
        "            Q_targets_next = self.qnetwork_target(next_states).max(1)[0].unsqueeze(1)\n",
        "            Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
        "\n",
        "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
        "\n",
        "        # loss = F.mse_loss(Q_expected, Q_targets)\n",
        "        loss = F.smooth_l1_loss(Q_expected, Q_targets)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.qnetwork_local.parameters(), 10.0)\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # CRITICAL: Clean up to prevent memory leak\n",
        "        del states, actions, rewards, next_states, dones, Q_targets, Q_expected, loss\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# --- üí• DQN Variant 2: Double DQN (Decoupled Target Calculation) ---\n",
        "# ----------------------------------------------------------------\n",
        "class DoubleDQNAgent(AgentBase):\n",
        "    \"\"\"Implements the Double DQN learning step.\"\"\"\n",
        "    def __init__(self, state_shape, action_size, seed):\n",
        "        super().__init__(state_shape, action_size, seed, mode='DoubleDQN', dueling=False)\n",
        "\n",
        "    def learn(self, experiences, gamma):\n",
        "        states, actions, rewards, next_states, dones = experiences\n",
        "\n",
        "        # Ensure states have the right shape\n",
        "        if states.dim() == 5:\n",
        "            states = states.squeeze(2)\n",
        "        if next_states.dim() == 5:\n",
        "            next_states = next_states.squeeze(2)\n",
        "\n",
        "        # Double DQN: Select actions with local, evaluate with target\n",
        "        with torch.no_grad():  # ‚Üê CRITICAL: No gradient tracking\n",
        "            # 1. Action selection from LOCAL network\n",
        "            Q_local_next = self.qnetwork_local(next_states)\n",
        "            best_actions = Q_local_next.max(1)[1].unsqueeze(1)\n",
        "\n",
        "            # 2. Value estimation from TARGET network\n",
        "            Q_targets_next = self.qnetwork_target(next_states).gather(1, best_actions)\n",
        "            Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
        "\n",
        "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
        "\n",
        "        loss = F.mse_loss(Q_expected, Q_targets)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # Clean up\n",
        "        del states, actions, rewards, next_states, dones, Q_targets, Q_expected, loss\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# --- üí• DQN Variant 3: Dueling DQN (Dueling Architecture + Double Learning Rule) ---\n",
        "# ----------------------------------------------------------------\n",
        "class DuelingDQNAgent(DoubleDQNAgent):\n",
        "    \"\"\"\n",
        "    DuelingDQN combines:\n",
        "    1. Dueling network architecture (separate Value and Advantage streams)\n",
        "    2. Double DQN learning rule (reduces overestimation)\n",
        "\n",
        "    This is typically the best-performing variant for Atari games.\n",
        "    \"\"\"\n",
        "    def __init__(self, state_shape, action_size, seed):\n",
        "        # Initialize with dueling=True to use dueling architecture\n",
        "        AgentBase.__init__(self, state_shape, action_size, seed, mode='DuelingDQN', dueling=True)\n",
        "\n",
        "    # Inherits the Double DQN learn() method for stability\n",
        "\n",
        "\n",
        "# --- Agent Initialization based on global CONFIG['MODE'] ---\n",
        "if CONFIG['MODE'] == \"SimpleDQN\":\n",
        "    agent = SimpleDQNAgent(state_shape=state_shape, action_size=action_size, seed=CONFIG['SEED'])\n",
        "elif CONFIG['MODE'] == \"DoubleDQN\":\n",
        "    agent = DoubleDQNAgent(state_shape=state_shape, action_size=action_size, seed=CONFIG['SEED'])\n",
        "elif CONFIG['MODE'] == \"DuelingDQN\":\n",
        "    agent = DuelingDQNAgent(state_shape=state_shape, action_size=action_size, seed=CONFIG['SEED'])\n",
        "else:\n",
        "    raise ValueError(\"Invalid MODE specified in CONFIG.\")\n",
        "\n",
        "print(f\"Initialized agent: {type(agent).__name__} with learning mode: {agent.mode}\")\n",
        "print_network_architecture(agent.qnetwork_local)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_loop"
      },
      "source": [
        "## 5. Training and Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "training_code"
      },
      "outputs": [],
      "source": [
        "def dqn_train(n_episodes=CONFIG['N_EPISODES'], max_t=10000, eps_start=CONFIG['EPS_START'], eps_end=CONFIG['EPS_END'], eps_decay=CONFIG['EPS_DECAY'], checkpoint_dir='/content/drive/MyDrive/DQN_Checkpoints'):\n",
        "    \"\"\"Deep Q-Learning with crash debugging.\"\"\"\n",
        "\n",
        "    import traceback\n",
        "\n",
        "    scores = []\n",
        "    scores_window = deque(maxlen=100)\n",
        "    eps = eps_start\n",
        "\n",
        "    best_avg_score = -float('inf')\n",
        "\n",
        "    global ALL_SCORES\n",
        "\n",
        "    print_config()\n",
        "\n",
        "    print(f\"\\nStarting training for {agent.mode}...\")\n",
        "    print(f\"LR: {CONFIG['LR']}, Buffer: {CONFIG['BUFFER_SIZE']}, Target Update: {CONFIG['TARGET_UPDATE_FREQ']}\")\n",
        "    print(f\"Checkpoints will be saved to: {checkpoint_dir}\")\n",
        "\n",
        "    try:\n",
        "        for i_episode in range(1, n_episodes + 1):\n",
        "            try:\n",
        "                # Monitor memory at start of episode\n",
        "                if i_episode % 10 == 0:\n",
        "                    mem = psutil.virtual_memory()\n",
        "                    gpu_mem = torch.cuda.memory_allocated() / (1024**3) if torch.cuda.is_available() else 0\n",
        "                    print(f'\\n[Ep {i_episode}] RAM: {mem.percent:.1f}% | GPU: {gpu_mem:.2f}GB | Buffer: {len(agent.memory)}/{CONFIG[\"BUFFER_SIZE\"]}')\n",
        "\n",
        "                state, info = env.reset(seed=CONFIG['SEED'] if i_episode == 1 else None)\n",
        "\n",
        "                # Check state validity\n",
        "                if state is None:\n",
        "                    print(f\"ERROR: Episode {i_episode} - env.reset() returned None!\")\n",
        "                    continue\n",
        "\n",
        "                state = np.array(state)\n",
        "\n",
        "                # Verify state shape\n",
        "                if state.shape != (4, 84, 84):\n",
        "                    print(f\"ERROR: Episode {i_episode} - Invalid state shape: {state.shape}\")\n",
        "                    continue\n",
        "\n",
        "                score = 0\n",
        "\n",
        "                for t in range(max_t):\n",
        "                    action = agent.act(state, eps)\n",
        "\n",
        "                    next_state_raw, reward, terminated, truncated, info = env.step(action)\n",
        "                    done = terminated or truncated\n",
        "\n",
        "                    next_state = np.array(next_state_raw)\n",
        "\n",
        "                    reward_np = np.array([reward]).astype(np.float32)\n",
        "                    done_np = np.array([done]).astype(np.uint8)\n",
        "\n",
        "                    agent.step(state, action, reward_np, next_state, done_np)\n",
        "                    state = next_state\n",
        "                    score += reward\n",
        "\n",
        "                    if done:\n",
        "                        break\n",
        "\n",
        "                scores_window.append(score)\n",
        "                scores.append(score)\n",
        "                eps = max(eps_end, eps_decay * eps)\n",
        "                avg_score = np.mean(scores_window)\n",
        "\n",
        "                # Adaptive Learning Rate: Reduce LR if performance plateaus\n",
        "                if i_episode == 600:\n",
        "                  for param_group in agent.optimizer.param_groups:\n",
        "                      param_group['lr'] = 2.5e-5  # Half again\n",
        "                  print(f\"\\n‚Üí Reduced LR to 2.5e-5 at episode {i_episode}\")\n",
        "\n",
        "                if i_episode == 1200:\n",
        "                    for param_group in agent.optimizer.param_groups:\n",
        "                        param_group['lr'] = 1e-5  # Very fine tuning\n",
        "                    print(f\"\\n‚Üí Reduced LR to 1e-5 at episode {i_episode}\")\n",
        "\n",
        "                # Print progress\n",
        "                if i_episode % 1 == 0:  # Print every episode for debugging\n",
        "                    print(f'\\rEpisode {i_episode}\\tScore: {score:.1f}\\tAvg: {avg_score:.2f}\\tEps: {eps:.3f}\\tSteps: {t+1}', end=\"\")\n",
        "\n",
        "                # Frequent checkpoints while debugging\n",
        "                if i_episode % CONFIG['CHECKPOINT_FREQ'] == 0:\n",
        "                    print(f'\\n[CHECKPOINT] Episode {i_episode}\\tAverage Score: {avg_score:.2f}')\n",
        "\n",
        "                    checkpoint = {\n",
        "                        'episode': i_episode,\n",
        "                        'model_state_dict': agent.qnetwork_local.state_dict(),\n",
        "                        'target_state_dict': agent.qnetwork_target.state_dict(),\n",
        "                        'optimizer_state_dict': agent.optimizer.state_dict(),\n",
        "                        'scores': scores,\n",
        "                        'eps': eps,\n",
        "                        'mode': agent.mode\n",
        "                    }\n",
        "                    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_{agent.mode}_ep{i_episode}.pth')\n",
        "                    torch.save(checkpoint, checkpoint_path)\n",
        "\n",
        "                    # Save best model separately\n",
        "                    if avg_score > best_avg_score:\n",
        "                        best_avg_score = avg_score\n",
        "                        best_path = os.path.join(checkpoint_dir, f'{agent.mode}_BEST.pth')\n",
        "                        torch.save(checkpoint, best_path)\n",
        "                        print(f'‚úì New best avg: {avg_score:.2f} - saved to {agent.mode}_BEST.pth')\n",
        "                    else:\n",
        "                        print(f'‚úì Checkpoint saved')\n",
        "\n",
        "                    # Aggressive memory cleanup\n",
        "                    gc.collect()\n",
        "                    if torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "\n",
        "                    mem = psutil.virtual_memory()\n",
        "                    print(f\"RAM: {mem.percent}% ({mem.available / (1024**3):.1f}GB free)\")\n",
        "\n",
        "                # Check for goal\n",
        "                if avg_score >= CONFIG['GOAL_SCORE']:\n",
        "                    print(f'\\nüéâ Goal Reached in {i_episode} episodes!')\n",
        "                    torch.save(agent.qnetwork_local.state_dict(), os.path.join(checkpoint_dir, f'{agent.mode}_solved_{i_episode}.pth'))\n",
        "                    break\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\n‚ùå ERROR in Episode {i_episode}:\")\n",
        "                print(f\"Exception: {type(e).__name__}: {e}\")\n",
        "                traceback.print_exc()\n",
        "\n",
        "                # Save emergency checkpoint\n",
        "                print(\"Saving emergency checkpoint...\")\n",
        "                torch.save({\n",
        "                    'episode': i_episode,\n",
        "                    'model_state_dict': agent.qnetwork_local.state_dict(),\n",
        "                    'scores': scores,\n",
        "                    'eps': eps,\n",
        "                }, os.path.join(checkpoint_dir, f'emergency_ep{i_episode}.pth'))\n",
        "\n",
        "                # Try to continue or break\n",
        "                user_input = input(\"Continue training? (y/n): \")\n",
        "                if user_input.lower() != 'y':\n",
        "                    break\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\n‚ö†Ô∏è  Training interrupted by user\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n\\n‚ùå FATAL ERROR:\")\n",
        "        print(f\"Exception: {type(e).__name__}: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "    finally:\n",
        "        # Always save what we have\n",
        "        print(\"\\n\\nSaving final results...\")\n",
        "        ALL_SCORES[f'{agent.mode}_optimized'] = scores  # Use unique key\n",
        "        np.save(os.path.join(checkpoint_dir, 'dqn_project_scores.npy'), ALL_SCORES)\n",
        "        print(f\"‚úì Saved {len(scores)} episodes\")\n",
        "        print(f\"‚úì Best average score achieved: {best_avg_score:.2f}\")\n",
        "\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Duelling DQN\n",
        "\n",
        "# ============================================================\n",
        "# DUELING DQN EXPERIMENT\n",
        "# ============================================================\n",
        "\n",
        "def run_dueling_dqn_experiment():\n",
        "    \"\"\"Complete DuelingDQN training pipeline.\"\"\"\n",
        "\n",
        "    global CONFIG, agent, env\n",
        "\n",
        "    # Set DuelingDQN config\n",
        "    CONFIG = CONFIG_DUELING.copy()\n",
        "\n",
        "    # Print configuration\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"EXPERIMENT: DuelingDQN (Target: 500+ Average)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    for key, value in CONFIG.items():\n",
        "        if isinstance(value, int) and value > 1000:\n",
        "            print(f\"{key:.<30} {value:,}\")\n",
        "        else:\n",
        "            print(f\"{key:.<30} {value}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Calculate epsilon milestones\n",
        "    print(\"\\nEpsilon Decay Schedule:\")\n",
        "    eps = CONFIG['EPS_START']\n",
        "    decay = CONFIG['EPS_DECAY']\n",
        "    for target_eps in [0.5, 0.2, 0.1, 0.05, 0.01]:\n",
        "        episodes = 0\n",
        "        temp_eps = eps\n",
        "        while temp_eps > target_eps:\n",
        "            temp_eps *= decay\n",
        "            episodes += 1\n",
        "        print(f\"  Epsilon reaches {target_eps:.2f} at episode ~{episodes}\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    # Close old environment if exists\n",
        "    try:\n",
        "        env.close()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Create fresh environment\n",
        "    env = make_atari_env(CONFIG['ENV_ID'], CONFIG['SEED'])\n",
        "    action_size = env.action_space.n\n",
        "    state_shape = env.observation_space.shape\n",
        "\n",
        "    print(f\"Environment: {CONFIG['ENV_ID']}\")\n",
        "    print(f\"State shape: {state_shape}\")\n",
        "    print(f\"Action space: {action_size} actions\\n\")\n",
        "\n",
        "    # Create DuelingDQN agent\n",
        "    agent = DuelingDQNAgent(state_shape=state_shape, action_size=action_size, seed=CONFIG['SEED'])\n",
        "\n",
        "    # Print network architecture\n",
        "    print_network_architecture(agent.qnetwork_local)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üöÄ Starting DuelingDQN Training...\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    # Train\n",
        "    scores = dqn_train(checkpoint_dir=checkpoint_dir)\n",
        "\n",
        "    # Cleanup\n",
        "    env.close()\n",
        "\n",
        "    return scores\n",
        "\n",
        "\n",
        "# When ready to run DuelingDQN:\n",
        "# scores_dueling = run_dueling_dqn_experiment()"
      ],
      "metadata": {
        "id": "S250tNTc0a8W"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "ThBy0kRg0uUx"
      },
      "outputs": [],
      "source": [
        "# Initialize an empty dictionary to hold scores from all runs\n",
        "ALL_SCORES = {}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resuming from checkpoint if it exists\n",
        "# Auto-resume from latest checkpoint\n",
        "\n",
        "checkpoint_files = glob.glob(os.path.join(checkpoint_dir, f'checkpoint_{CONFIG[\"MODE\"]}_ep*.pth'))\n",
        "\n",
        "if checkpoint_files:\n",
        "    # Sort to get the latest checkpoint\n",
        "    checkpoint_files.sort(key=lambda x: int(x.split('_ep')[-1].split('.')[0]))\n",
        "    latest_checkpoint = checkpoint_files[-1]\n",
        "\n",
        "    print(f\"\\nüîÑ Found existing checkpoint: {os.path.basename(latest_checkpoint)}\")\n",
        "    print(f\"üìÅ Location: {checkpoint_dir}\")\n",
        "\n",
        "    # Option to resume or start fresh\n",
        "    resume = input(\"Resume from checkpoint? (y/n): \").lower() == 'y'\n",
        "\n",
        "    if resume:\n",
        "        print(f\"Loading checkpoint...\")\n",
        "        checkpoint = torch.load(latest_checkpoint)\n",
        "\n",
        "        agent.qnetwork_local.load_state_dict(checkpoint['model_state_dict'])\n",
        "        agent.qnetwork_target.load_state_dict(checkpoint['target_state_dict'])\n",
        "        agent.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "        # Load previous scores\n",
        "        scores_path = os.path.join(checkpoint_dir, 'dqn_project_scores.npy')\n",
        "        if os.path.exists(scores_path):\n",
        "            ALL_SCORES = np.load(scores_path, allow_pickle=True).item()\n",
        "\n",
        "        start_episode = checkpoint['episode']\n",
        "        start_eps = checkpoint['eps']\n",
        "\n",
        "        print(f\"‚úì Resumed from episode {start_episode}\")\n",
        "        print(f\"‚úì Previous scores loaded: {len(checkpoint['scores'])} episodes\")\n",
        "        print(f\"‚úì Epsilon: {start_eps:.4f}\")\n",
        "        if len(checkpoint['scores']) >= 100:\n",
        "            print(f\"‚úì Last 100 episodes avg: {np.mean(checkpoint['scores'][-100:]):.2f}\")\n",
        "\n",
        "        # Update CONFIG to continue from where we left off\n",
        "        CONFIG['EPS_START'] = start_eps\n",
        "    else:\n",
        "        print(\"Starting fresh training...\")\n",
        "else:\n",
        "    print(\"No checkpoint found. Starting fresh training...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTnFGVp3Bp9c",
        "outputId": "52ca50e3-c403-4a99-ed0d-4ec31248014c"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÑ Found existing checkpoint: checkpoint_SimpleDQN_ep2800.pth\n",
            "üìÅ Location: /content/drive/MyDrive/DQN_Checkpoints\n",
            "Resume from checkpoint? (y/n): n\n",
            "Starting fresh training...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P87GiE140uUx",
        "outputId": "00e5e7d5-999c-44ed-ea7a-5b2447e037ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "EXPERIMENT: DuelingDQN (Target: 500+ Average)\n",
            "======================================================================\n",
            "ENV_ID........................ ALE/SpaceInvaders-v5\n",
            "SEED.......................... 999\n",
            "MODE.......................... DuelingDQN\n",
            "INPUT_SHAPE................... (4, 84, 84)\n",
            "BUFFER_SIZE................... 50,000\n",
            "BATCH_SIZE.................... 64\n",
            "GAMMA......................... 0.99\n",
            "TAU........................... 0.001\n",
            "LR............................ 0.00025\n",
            "UPDATE_EVERY.................. 4\n",
            "TARGET_UPDATE_FREQ............ 1000\n",
            "N_EPISODES.................... 5,000\n",
            "EPS_START..................... 1.0\n",
            "EPS_END....................... 0.01\n",
            "EPS_DECAY..................... 0.9996\n",
            "USE_GOOGLE_DRIVE.............. True\n",
            "CHECKPOINT_FREQ............... 100\n",
            "GOAL_SCORE.................... 400.0\n",
            "======================================================================\n",
            "\n",
            "Epsilon Decay Schedule:\n",
            "  Epsilon reaches 0.50 at episode ~1733\n",
            "  Epsilon reaches 0.20 at episode ~4023\n",
            "  Epsilon reaches 0.10 at episode ~5756\n",
            "  Epsilon reaches 0.05 at episode ~7488\n",
            "  Epsilon reaches 0.01 at episode ~11511\n",
            "======================================================================\n",
            "\n",
            "Environment: ALE/SpaceInvaders-v5\n",
            "State shape: (4, 84, 84)\n",
            "Action space: 6 actions\n",
            "\n",
            "\n",
            "======================================================================\n",
            "NEURAL NETWORK ARCHITECTURE\n",
            "======================================================================\n",
            "QNetwork(\n",
            "  (conv1): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc_v1): Linear(in_features=6272, out_features=512, bias=True)\n",
            "  (fc_v2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc_v3): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (fc_a1): Linear(in_features=6272, out_features=512, bias=True)\n",
            "  (fc_a2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc_a3): Linear(in_features=256, out_features=6, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            ")\n",
            "======================================================================\n",
            "\n",
            "Total Parameters:      6,803,367\n",
            "Trainable Parameters:  6,803,367\n",
            "Architecture Type:     Dueling\n",
            "\n",
            "Layer Output Shapes:\n",
            "  Conv output:  torch.Size([1, 6272])\n",
            "  Final output: torch.Size([1, 6])\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "üöÄ Starting DuelingDQN Training...\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "CURRENT CONFIGURATION - SimpleDQN Aggressive\n",
            "======================================================================\n",
            "Environment:          ALE/SpaceInvaders-v5\n",
            "Seed:                 999\n",
            "Mode:                 DuelingDQN\n",
            "Buffer Size:          50,000 experiences\n",
            "Batch Size:           64\n",
            "Learning Rate:        0.00025\n",
            "Gamma:                0.99\n",
            "Update Every:         4 steps\n",
            "Target Update Freq:   1000 steps\n",
            "Episodes:             5000\n",
            "Epsilon Start:        1.0\n",
            "Epsilon End:          0.01\n",
            "Epsilon Decay:        0.9996\n",
            "Checkpoint Freq:      100 episodes\n",
            "======================================================================\n",
            "\n",
            "Starting training for DuelingDQN...\n",
            "LR: 0.00025, Buffer: 50000, Target Update: 1000\n",
            "Checkpoints will be saved to: /content/drive/MyDrive/DQN_Checkpoints\n",
            "Episode 9\tScore: 30.0\tAvg: 57.22\tEps: 0.996\tSteps: 146\n",
            "[Ep 10] RAM: 29.4% | GPU: 0.18GB | Buffer: 2072/50000\n",
            "Episode 19\tScore: 80.0\tAvg: 46.84\tEps: 0.992\tSteps: 412\n",
            "[Ep 20] RAM: 29.3% | GPU: 0.18GB | Buffer: 3949/50000\n",
            "Episode 29\tScore: 20.0\tAvg: 46.03\tEps: 0.988\tSteps: 261\n",
            "[Ep 30] RAM: 29.3% | GPU: 0.18GB | Buffer: 5791/50000\n",
            "Episode 39\tScore: 15.0\tAvg: 56.79\tEps: 0.985\tSteps: 144\n",
            "[Ep 40] RAM: 29.3% | GPU: 0.18GB | Buffer: 8004/50000\n",
            "Episode 49\tScore: 30.0\tAvg: 60.10\tEps: 0.981\tSteps: 118\n",
            "[Ep 50] RAM: 29.3% | GPU: 0.18GB | Buffer: 9928/50000\n",
            "Episode 59\tScore: 15.0\tAvg: 73.31\tEps: 0.977\tSteps: 173\n",
            "[Ep 60] RAM: 29.3% | GPU: 0.18GB | Buffer: 12921/50000\n",
            "Episode 69\tScore: 105.0\tAvg: 69.06\tEps: 0.973\tSteps: 278\n",
            "[Ep 70] RAM: 29.3% | GPU: 0.18GB | Buffer: 14747/50000\n",
            "Episode 79\tScore: 25.0\tAvg: 66.58\tEps: 0.969\tSteps: 160\n",
            "[Ep 80] RAM: 29.3% | GPU: 0.18GB | Buffer: 16449/50000\n",
            "Episode 89\tScore: 35.0\tAvg: 64.83\tEps: 0.965\tSteps: 134\n",
            "[Ep 90] RAM: 29.2% | GPU: 0.18GB | Buffer: 18319/50000\n",
            "Episode 99\tScore: 25.0\tAvg: 62.37\tEps: 0.961\tSteps: 101\n",
            "[Ep 100] RAM: 29.2% | GPU: 0.18GB | Buffer: 19902/50000\n",
            "Episode 100\tScore: 105.0\tAvg: 62.80\tEps: 0.961\tSteps: 262\n",
            "[CHECKPOINT] Episode 100\tAverage Score: 62.80\n",
            "‚úì New best avg: 62.80 - saved to DuelingDQN_BEST.pth\n",
            "RAM: 29.3% (37.5GB free)\n",
            "Episode 109\tScore: 5.0\tAvg: 60.55\tEps: 0.957\tSteps: 144\n",
            "[Ep 110] RAM: 29.3% | GPU: 0.18GB | Buffer: 21534/50000\n",
            "Episode 119\tScore: 50.0\tAvg: 65.15\tEps: 0.954\tSteps: 189\n",
            "[Ep 120] RAM: 29.3% | GPU: 0.18GB | Buffer: 23597/50000\n",
            "Episode 129\tScore: 0.0\tAvg: 64.45\tEps: 0.950\tSteps: 118\n",
            "[Ep 130] RAM: 29.3% | GPU: 0.18GB | Buffer: 25363/50000\n",
            "Episode 139\tScore: 50.0\tAvg: 60.60\tEps: 0.946\tSteps: 155\n",
            "[Ep 140] RAM: 29.3% | GPU: 0.18GB | Buffer: 26914/50000\n",
            "Episode 149\tScore: 75.0\tAvg: 57.20\tEps: 0.942\tSteps: 135\n",
            "[Ep 150] RAM: 29.3% | GPU: 0.18GB | Buffer: 28481/50000\n",
            "Episode 159\tScore: 5.0\tAvg: 46.65\tEps: 0.938\tSteps: 132\n",
            "[Ep 160] RAM: 29.4% | GPU: 0.18GB | Buffer: 30092/50000\n",
            "Episode 169\tScore: 50.0\tAvg: 47.55\tEps: 0.935\tSteps: 174\n",
            "[Ep 170] RAM: 29.3% | GPU: 0.18GB | Buffer: 31982/50000\n",
            "Episode 179\tScore: 0.0\tAvg: 47.20\tEps: 0.931\tSteps: 87\n",
            "[Ep 180] RAM: 29.3% | GPU: 0.18GB | Buffer: 34039/50000\n",
            "Episode 189\tScore: 75.0\tAvg: 48.05\tEps: 0.927\tSteps: 151\n",
            "[Ep 190] RAM: 29.3% | GPU: 0.18GB | Buffer: 35836/50000\n",
            "Episode 199\tScore: 30.0\tAvg: 50.70\tEps: 0.923\tSteps: 202\n",
            "[Ep 200] RAM: 29.3% | GPU: 0.18GB | Buffer: 38100/50000\n",
            "Episode 200\tScore: 25.0\tAvg: 49.90\tEps: 0.923\tSteps: 157\n",
            "[CHECKPOINT] Episode 200\tAverage Score: 49.90\n",
            "‚úì Checkpoint saved\n",
            "RAM: 29.3% (37.5GB free)\n",
            "Episode 209\tScore: 10.0\tAvg: 52.65\tEps: 0.920\tSteps: 158\n",
            "[Ep 210] RAM: 29.3% | GPU: 0.18GB | Buffer: 40102/50000\n",
            "Episode 219\tScore: 55.0\tAvg: 51.05\tEps: 0.916\tSteps: 221\n",
            "[Ep 220] RAM: 29.3% | GPU: 0.18GB | Buffer: 42233/50000\n",
            "Episode 229\tScore: 50.0\tAvg: 52.50\tEps: 0.912\tSteps: 148\n",
            "[Ep 230] RAM: 29.3% | GPU: 0.18GB | Buffer: 43970/50000\n",
            "Episode 239\tScore: 15.0\tAvg: 50.35\tEps: 0.909\tSteps: 148\n",
            "[Ep 240] RAM: 29.3% | GPU: 0.18GB | Buffer: 45439/50000\n",
            "Episode 249\tScore: 60.0\tAvg: 52.25\tEps: 0.905\tSteps: 266\n",
            "[Ep 250] RAM: 29.3% | GPU: 0.18GB | Buffer: 47293/50000\n",
            "Episode 259\tScore: 40.0\tAvg: 53.75\tEps: 0.902\tSteps: 143\n",
            "[Ep 260] RAM: 29.3% | GPU: 0.18GB | Buffer: 49187/50000\n",
            "Episode 269\tScore: 80.0\tAvg: 60.70\tEps: 0.898\tSteps: 194\n",
            "[Ep 270] RAM: 29.3% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 279\tScore: 50.0\tAvg: 60.70\tEps: 0.894\tSteps: 159\n",
            "[Ep 280] RAM: 29.3% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 289\tScore: 145.0\tAvg: 62.75\tEps: 0.891\tSteps: 420\n",
            "[Ep 290] RAM: 29.3% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 299\tScore: 25.0\tAvg: 61.55\tEps: 0.887\tSteps: 192\n",
            "[Ep 300] RAM: 29.3% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 300\tScore: 50.0\tAvg: 61.80\tEps: 0.887\tSteps: 212\n",
            "[CHECKPOINT] Episode 300\tAverage Score: 61.80\n",
            "‚úì Checkpoint saved\n",
            "RAM: 29.3% (37.4GB free)\n",
            "Episode 309\tScore: 35.0\tAvg: 61.20\tEps: 0.884\tSteps: 183\n",
            "[Ep 310] RAM: 29.3% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 319\tScore: 55.0\tAvg: 61.75\tEps: 0.880\tSteps: 198\n",
            "[Ep 320] RAM: 29.3% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 329\tScore: 30.0\tAvg: 60.20\tEps: 0.877\tSteps: 222\n",
            "[Ep 330] RAM: 29.3% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 339\tScore: 0.0\tAvg: 64.25\tEps: 0.873\tSteps: 124\n",
            "[Ep 340] RAM: 29.3% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 349\tScore: 55.0\tAvg: 63.50\tEps: 0.870\tSteps: 178\n",
            "[Ep 350] RAM: 29.3% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 359\tScore: 445.0\tAvg: 72.65\tEps: 0.866\tSteps: 497\n",
            "[Ep 360] RAM: 29.3% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 369\tScore: 5.0\tAvg: 65.55\tEps: 0.863\tSteps: 195\n",
            "[Ep 370] RAM: 29.3% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 379\tScore: 15.0\tAvg: 69.85\tEps: 0.859\tSteps: 110\n",
            "[Ep 380] RAM: 29.3% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 389\tScore: 65.0\tAvg: 65.00\tEps: 0.856\tSteps: 147\n",
            "[Ep 390] RAM: 29.3% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 399\tScore: 15.0\tAvg: 66.75\tEps: 0.852\tSteps: 172\n",
            "[Ep 400] RAM: 29.3% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 400\tScore: 15.0\tAvg: 66.40\tEps: 0.852\tSteps: 132\n",
            "[CHECKPOINT] Episode 400\tAverage Score: 66.40\n",
            "‚úì New best avg: 66.40 - saved to DuelingDQN_BEST.pth\n",
            "RAM: 29.3% (37.4GB free)\n",
            "Episode 409\tScore: 75.0\tAvg: 66.95\tEps: 0.849\tSteps: 137\n",
            "[Ep 410] RAM: 29.3% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 419\tScore: 20.0\tAvg: 65.55\tEps: 0.846\tSteps: 109\n",
            "[Ep 420] RAM: 29.5% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 429\tScore: 15.0\tAvg: 69.00\tEps: 0.842\tSteps: 156\n",
            "[Ep 430] RAM: 29.5% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 439\tScore: 5.0\tAvg: 67.00\tEps: 0.839\tSteps: 130\n",
            "[Ep 440] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 449\tScore: 90.0\tAvg: 66.90\tEps: 0.836\tSteps: 207\n",
            "[Ep 450] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 459\tScore: 105.0\tAvg: 58.50\tEps: 0.832\tSteps: 262\n",
            "[Ep 460] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 469\tScore: 15.0\tAvg: 60.55\tEps: 0.829\tSteps: 128\n",
            "[Ep 470] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 479\tScore: 10.0\tAvg: 59.00\tEps: 0.826\tSteps: 178\n",
            "[Ep 480] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 489\tScore: 160.0\tAvg: 63.95\tEps: 0.822\tSteps: 417\n",
            "[Ep 490] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 499\tScore: 110.0\tAvg: 63.20\tEps: 0.819\tSteps: 286\n",
            "[Ep 500] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 500\tScore: 5.0\tAvg: 63.10\tEps: 0.819\tSteps: 89\n",
            "[CHECKPOINT] Episode 500\tAverage Score: 63.10\n",
            "‚úì Checkpoint saved\n",
            "RAM: 29.4% (37.4GB free)\n",
            "Episode 509\tScore: 75.0\tAvg: 61.90\tEps: 0.816\tSteps: 169\n",
            "[Ep 510] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 519\tScore: 15.0\tAvg: 62.75\tEps: 0.812\tSteps: 168\n",
            "[Ep 520] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 529\tScore: 55.0\tAvg: 62.00\tEps: 0.809\tSteps: 184\n",
            "[Ep 530] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 539\tScore: 5.0\tAvg: 66.55\tEps: 0.806\tSteps: 163\n",
            "[Ep 540] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 549\tScore: 105.0\tAvg: 69.60\tEps: 0.803\tSteps: 313\n",
            "[Ep 550] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 559\tScore: 25.0\tAvg: 68.95\tEps: 0.800\tSteps: 127\n",
            "[Ep 560] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 569\tScore: 0.0\tAvg: 69.55\tEps: 0.796\tSteps: 68\n",
            "[Ep 570] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 579\tScore: 5.0\tAvg: 66.05\tEps: 0.793\tSteps: 148\n",
            "[Ep 580] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 589\tScore: 50.0\tAvg: 61.95\tEps: 0.790\tSteps: 158\n",
            "[Ep 590] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 599\tScore: 0.0\tAvg: 59.05\tEps: 0.787\tSteps: 59\n",
            "[Ep 600] RAM: 29.5% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "\n",
            "‚Üí Reduced LR to 2.5e-5 at episode 600\n",
            "Episode 600\tScore: 30.0\tAvg: 59.30\tEps: 0.787\tSteps: 137\n",
            "[CHECKPOINT] Episode 600\tAverage Score: 59.30\n",
            "‚úì Checkpoint saved\n",
            "RAM: 29.4% (37.4GB free)\n",
            "Episode 609\tScore: 90.0\tAvg: 59.05\tEps: 0.784\tSteps: 230\n",
            "[Ep 610] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 619\tScore: 15.0\tAvg: 57.10\tEps: 0.781\tSteps: 168\n",
            "[Ep 620] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 629\tScore: 15.0\tAvg: 53.95\tEps: 0.778\tSteps: 128\n",
            "[Ep 630] RAM: 29.5% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 639\tScore: 0.0\tAvg: 50.30\tEps: 0.774\tSteps: 118\n",
            "[Ep 640] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 649\tScore: 40.0\tAvg: 45.25\tEps: 0.771\tSteps: 145\n",
            "[Ep 650] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 659\tScore: 20.0\tAvg: 45.45\tEps: 0.768\tSteps: 131\n",
            "[Ep 660] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 669\tScore: 45.0\tAvg: 45.35\tEps: 0.765\tSteps: 191\n",
            "[Ep 670] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 679\tScore: 130.0\tAvg: 49.65\tEps: 0.762\tSteps: 214\n",
            "[Ep 680] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 689\tScore: 45.0\tAvg: 50.00\tEps: 0.759\tSteps: 188\n",
            "[Ep 690] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 699\tScore: 75.0\tAvg: 50.30\tEps: 0.756\tSteps: 166\n",
            "[Ep 700] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 700\tScore: 75.0\tAvg: 50.75\tEps: 0.756\tSteps: 182\n",
            "[CHECKPOINT] Episode 700\tAverage Score: 50.75\n",
            "‚úì Checkpoint saved\n",
            "RAM: 29.4% (37.4GB free)\n",
            "Episode 709\tScore: 20.0\tAvg: 49.30\tEps: 0.753\tSteps: 133\n",
            "[Ep 710] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 719\tScore: 50.0\tAvg: 52.45\tEps: 0.750\tSteps: 175\n",
            "[Ep 720] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 729\tScore: 85.0\tAvg: 52.85\tEps: 0.747\tSteps: 266\n",
            "[Ep 730] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 739\tScore: 15.0\tAvg: 55.60\tEps: 0.744\tSteps: 157\n",
            "[Ep 740] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 749\tScore: 25.0\tAvg: 57.95\tEps: 0.741\tSteps: 154\n",
            "[Ep 750] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 759\tScore: 360.0\tAvg: 60.75\tEps: 0.738\tSteps: 407\n",
            "[Ep 760] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 769\tScore: 120.0\tAvg: 58.60\tEps: 0.735\tSteps: 424\n",
            "[Ep 770] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 779\tScore: 90.0\tAvg: 53.80\tEps: 0.732\tSteps: 271\n",
            "[Ep 780] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 789\tScore: 0.0\tAvg: 54.05\tEps: 0.729\tSteps: 63\n",
            "[Ep 790] RAM: 29.4% | GPU: 0.18GB | Buffer: 50000/50000\n",
            "Episode 798\tScore: 25.0\tAvg: 53.85\tEps: 0.727\tSteps: 205\n",
            "\n",
            "‚ö†Ô∏è  Training interrupted by user\n",
            "\n",
            "\n",
            "Saving final results...\n",
            "‚úì Saved 798 episodes\n",
            "‚úì Best average score achieved: 66.40\n"
          ]
        }
      ],
      "source": [
        "# Run training\n",
        "# Simple DQN\n",
        "# scores = dqn_train()\n",
        "\n",
        "# Duelling DQN\n",
        "scores_dueling = run_dueling_dqn_experiment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "kU5ktOld0uUy"
      },
      "outputs": [],
      "source": [
        "def plot_all_dqn_scores(all_scores_dict, window=100):\n",
        "    \"\"\"\n",
        "    Loads scores for all DQN variants and plots their moving average on a single graph.\n",
        "\n",
        "    Args:\n",
        "        all_scores_dict (dict): Dictionary mapping mode names ('SimpleDQN', etc.) to lists of episode scores.\n",
        "        window (int): The window size for the moving average.\n",
        "    \"\"\"\n",
        "    if not all_scores_dict:\n",
        "        print(\"No scores available to plot. Please run training for at least one agent.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    for mode, scores in all_scores_dict.items():\n",
        "        if len(scores) >= window:\n",
        "            # Calculate 100-episode moving average\n",
        "            moving_avg = np.convolve(scores, np.ones(window)/window, mode='valid')\n",
        "\n",
        "            # The x-axis should start at the window size, as the moving average starts there\n",
        "            x_axis = np.arange(len(moving_avg)) + window\n",
        "\n",
        "            plt.plot(x_axis, moving_avg, label=f'{mode} (Avg={moving_avg[-1]:.2f})')\n",
        "        else:\n",
        "            print(f\"Not enough data to calculate moving average for {mode}.\")\n",
        "\n",
        "    # Add score targets as horizontal lines, similar to the presentation graph\n",
        "    plt.axhline(y=400, color='r', linestyle='--', linewidth=1, label='Goal: 400')\n",
        "    plt.axhline(y=500, color='g', linestyle='--', linewidth=1, label='Goal: 500')\n",
        "\n",
        "    plt.title('Consolidated DQN Training Progress (100-Episode Moving Average)')\n",
        "    plt.ylabel('Average Score (100-Game Window)')\n",
        "    plt.xlabel('Episode #')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.savefig('all_dqn_scores.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "6jC9Nqis0uUy",
        "outputId": "5d69d7cd-1ed7-4a9c-8c8a-7bec3aed9c80"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Run run AFTER you have completed at least one training run\n",
        "try:\n",
        "    # Load saved scores (if they exist from previous runs)\n",
        "    scores_path = '/content/drive/MyDrive/DQN_Checkpoints/dqn_project_scores.npy'\n",
        "    loaded_scores = np.load(scores_path, allow_pickle=True).item()\n",
        "    plot_all_dqn_scores(loaded_scores)\n",
        "except FileNotFoundError:\n",
        "    print(\"Scores file not found. Run training first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "video_display"
      },
      "source": [
        "## 6. Video Visualization Utility\n",
        "This function is provided for optional video recording using a trained model's weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "video_code"
      },
      "outputs": [],
      "source": [
        "def render_mp4(videopath: str) -> str:\n",
        "  \"\"\"Gets a string containing a b64-encoded version of the MP4 video.\"\"\"\n",
        "  import os\n",
        "  if not os.path.exists(videopath):\n",
        "      return f\"<p>Video file not found at {videopath}. Run a test episode first.</p>\"\n",
        "\n",
        "  mp4 = open(videopath, 'rb').read()\n",
        "  base64_encoded_mp4 = b64encode(mp4).decode()\n",
        "  return f'<video width=400 controls><source src=\"data:video/mp4;base64,{base64_encoded_mp4}\" type=\"video/mp4\"></video>'\n",
        "\n",
        "def run_and_record(env_id, weights_path, mode, seed=CONFIG['SEED'], num_episodes=1):\n",
        "    \"\"\"Runs a specified agent on the environment and records the interaction.\"\"\"\n",
        "\n",
        "    # 1. Setup Environment\n",
        "    # Use the same wrapper stack as training for consistent state representation\n",
        "    env_render = make_atari_env(env_id, seed=seed)\n",
        "\n",
        "    # 2. Setup Agent\n",
        "    action_size = env_render.action_space.n\n",
        "    state_shape = env_render.observation_space.shape\n",
        "\n",
        "    # Use the appropriate Agent class\n",
        "    if mode == \"SimpleDQN\":\n",
        "        test_agent = SimpleDQNAgent(state_shape, action_size, seed)\n",
        "    elif mode == \"DoubleDQN\":\n",
        "        test_agent = DoubleDQNAgent(state_shape, action_size, seed)\n",
        "    elif mode == \"DuelingDQN\":\n",
        "        test_agent = DuelingDQNAgent(state_shape, action_size, seed)\n",
        "    else:\n",
        "        return f\"<p>Invalid MODE specified for testing: {mode}</p>\"\n",
        "\n",
        "    # 3. Load Weights\n",
        "    try:\n",
        "        test_agent.qnetwork_local.load_state_dict(torch.load(weights_path, map_location=device))\n",
        "        test_agent.qnetwork_local.eval()\n",
        "        print(f\"Successfully loaded {mode} weights from {weights_path}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Checkpoint file {weights_path} not found. Agent will use random weights.\")\n",
        "        return\n",
        "\n",
        "    # 4. Record Episodes\n",
        "    video_path = f'{mode}_{env_id.split(\"/\")[-1]}_test.mp4'\n",
        "    frames = []\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        state, info = env_render.reset(seed=seed)\n",
        "        score = 0\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            # The FrameStack wrapper returns a LazyFrame, convert to NumPy array\n",
        "            state_np = np.array(state)\n",
        "            action = test_agent.act(state_np, eps=0.0)\n",
        "\n",
        "            # Capture frame (convert to RGB before saving)\n",
        "            frames.append(env_render.render())\n",
        "\n",
        "            next_state, reward, terminated, truncated, info = env_render.step(action)\n",
        "            done = terminated or truncated\n",
        "            state = next_state\n",
        "            score += reward\n",
        "\n",
        "        print(f\"Test Episode {episode+1} score: {score:.2f}\")\n",
        "\n",
        "    env_render.close()\n",
        "\n",
        "    # Save video\n",
        "    imageio.mimsave(video_path, frames, fps=30)\n",
        "\n",
        "    # Display video\n",
        "    html = render_mp4(video_path)\n",
        "    ipythondisplay.display(ipythondisplay.HTML(html))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "1FJMkbNG0uUy"
      },
      "outputs": [],
      "source": [
        "# Example usage (Uncomment and update weights_path after training):\n",
        "# run_and_record(CONFIG['ENV_ID'], '/content/drive/MyDrive/DQN_Checkpoints/SimpleDQN_BEST.pth', 'SimpleDQN', num_episodes=1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "name": "AIDL_B02_DQN_SpaceInvaders_Variants_Clean.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}